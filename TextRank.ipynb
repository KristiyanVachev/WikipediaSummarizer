{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = {\n",
    "    'webpage-1': set(['webpage-2', 'webpage-4', 'webpage-5', 'webpage-6', 'webpage-8', 'webpage-9', 'webpage-10']),\n",
    "    'webpage-2': set(['webpage-5', 'webpage-6']),\n",
    "    'webpage-3': set(['webpage-10']),\n",
    "    'webpage-4': set(['webpage-9']),\n",
    "    'webpage-5': set(['webpage-2', 'webpage-4']),\n",
    "    'webpage-6': set([]), # dangling page\n",
    "    'webpage-7': set(['webpage-1', 'webpage-3', 'webpage-4']),\n",
    "    'webpage-8': set(['webpage-1']),\n",
    "    'webpage-9': set(['webpage-1', 'webpage-2', 'webpage-3', 'webpage-8', 'webpage-10']),\n",
    "    'webpage-10': set(['webpage-2', 'webpage-3', 'webpage-8', 'webpage-9']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'webpage-1': 0, 'webpage-2': 1, 'webpage-3': 2, 'webpage-4': 3, 'webpage-5': 4, 'webpage-6': 5, 'webpage-7': 6, 'webpage-8': 7, 'webpage-9': 8, 'webpage-10': 9}\n"
     ]
    }
   ],
   "source": [
    "def build_index(links):\n",
    "    website_list = links.keys()\n",
    "    return {website: index for index, website in enumerate(website_list)}\n",
    " \n",
    "website_index = build_index(links)\n",
    "print(website_index)\n",
    "# {'webpage-10': 3, 'webpage-9': 0, 'webpage-8': 1, 'webpage-1': 2, 'webpage-3': 4, 'webpage-2': 5, 'webpage-5': 6, 'webpage-4': 7, 'webpage-7': 8, 'webpage-6': 9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.14285714 0.         0.14285714 0.14285714 0.14285714\n",
      "  0.         0.14285714 0.14285714 0.14285714]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.        ]\n",
      " [0.         0.5        0.         0.5        0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.1        0.1        0.1        0.1        0.1        0.1\n",
      "  0.1        0.1        0.1        0.1       ]\n",
      " [0.33333333 0.         0.33333333 0.33333333 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.2        0.2        0.2        0.         0.         0.\n",
      "  0.         0.2        0.         0.2       ]\n",
      " [0.         0.25       0.25       0.         0.         0.\n",
      "  0.         0.25       0.25       0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "def build_transition_matrix(links, index):\n",
    "    total_links = 0\n",
    "    A = np.zeros((len(index), len(index)))\n",
    "    for webpage in links:\n",
    "        # dangling page\n",
    "        if not links[webpage]:\n",
    "            # Assign equal probabilities to transition to all the other pages\n",
    "            A[index[webpage]] = np.ones(len(index)) / len(index)\n",
    "        else:\n",
    "            for dest_webpage in links[webpage]:\n",
    "                total_links += 1\n",
    "                A[index[webpage]][index[dest_webpage]] = 1.0 / len(links[webpage])\n",
    " \n",
    "    return A\n",
    " \n",
    "A = build_transition_matrix(links, website_index)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [0.1300934  0.1305122  0.08116465 0.085402   0.09427366 0.09427366\n",
      " 0.02301397 0.09044235 0.13933698 0.13148714]\n",
      "1.0\n",
      "[8, 9, 1, 0, 4, 5, 7, 3, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "def pagerank(A, eps=0.0001, d=0.85):\n",
    "    P = np.ones(len(A)) / len(A)\n",
    "    while True:\n",
    "        new_P = np.ones(len(A)) * (1 - d) / len(A) + d * A.T.dot(P)\n",
    "        delta = abs(new_P - P).sum()\n",
    "        if delta <= eps:\n",
    "            return new_P\n",
    "        P = new_P\n",
    " \n",
    "results = pagerank(A)\n",
    " \n",
    "print(\"Results:\", results) # [ 0.13933698,  0.09044235,  0.1300934 ,  0.13148714,  0.08116465, 0.1305122 ,  0.09427366,  0.085402  ,  0.02301397,  0.09427366]\n",
    "print(sum(results)) # 1.0\n",
    "print([item[0] for item in sorted(enumerate(results), key=lambda item: -item[1])]) # [0, 3, 5, 2, 6, 9, 1, 7, 4, 8]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999999999999998\n",
      "0.4999999999999999\n",
      "0.9999999999999998\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    " \n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "# One out of 5 words differ => 0.8 similarity\n",
    "print(sentence_similarity(\"This is a good sentence\".split(), \"This is a bad sentence\".split()))\n",
    " \n",
    "# One out of 2 non-stop words differ => 0.5 similarity\n",
    "print(sentence_similarity(\"This is a good sentence\".split(), \"This is a bad sentence\".split(), stopwords.words('english')))\n",
    " \n",
    "# 0 out of 2 non-stop words differ => 1 similarity (identical sentences)\n",
    "print(sentence_similarity(\"This is a good sentence\".split(), \"This is a good sentence\".split(), stopwords.words('english')))\n",
    " \n",
    "# Completely different sentences=> 0.0\n",
    "print(sentence_similarity(\"This is a good sentence\".split(), \"I want to go to the market\".split(), stopwords.words('english')))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
      "98\n",
      "[[0.         0.02171602 0.02438459 ... 0.01056602 0.02113203 0.0224139 ]\n",
      " [0.01642812 0.         0.00853223 ... 0.00646989 0.01940966 0.0137247 ]\n",
      " [0.0326456  0.01509956 0.         ... 0.00642841 0.01928522 0.02727342]\n",
      " ...\n",
      " [0.0154814  0.01253106 0.00703547 ... 0.         0.03200945 0.0150894 ]\n",
      " [0.01453939 0.01765287 0.00991107 ... 0.01503088 0.         0.02125687]\n",
      " [0.0179617  0.01453869 0.01632527 ... 0.00825283 0.02475849 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "  \n",
    "# Get a text from the Brown Corpus\n",
    "sentences = brown.sents('ca01')\n",
    " \n",
    "print(sentences)\n",
    "# [[u'The', u'Fulton', u'County', u'Grand', u'Jury', u'said', u'Friday', u'an', u'investigation', u'of', u\"Atlanta's\", u'recent', u'primary', u'election', u'produced', u'``', u'no', u'evidence', u\"''\", u'that', u'any', u'irregularities', u'took', u'place', u'.'], [u'The', u'jury', u'further', u'said', u'in', u'term-end', u'presentments', u'that', u'the', u'City', u'Executive', u'Committee', u',', u'which', u'had', u'over-all', u'charge', u'of', u'the', u'election', u',', u'``', u'deserves', u'the', u'praise', u'and', u'thanks', u'of', u'the', u'City', u'of', u'Atlanta', u\"''\", u'for', u'the', u'manner', u'in', u'which', u'the', u'election', u'was', u'conducted', u'.'], ...]\n",
    " \n",
    "print(len(sentences))  #  98\n",
    " \n",
    "# get the english list of stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def build_similarity_matrix(sentences, stopwords=None):\n",
    "    # Create an empty similarity matrix\n",
    "    S = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    " \n",
    "            S[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    " \n",
    "    # normalize the matrix row-wise\n",
    "    for idx in range(len(S)):\n",
    "        S[idx] /= S[idx].sum()\n",
    " \n",
    "    return S\n",
    " \n",
    "S = build_similarity_matrix(sentences, stop_words)    \n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01121618 0.01416586 0.00875955 0.01720666 0.01097157 0.00992082\n",
      " 0.01200115 0.00168689 0.01309704 0.01454477 0.01097302 0.00816622\n",
      " 0.00878952 0.00681878 0.01487246 0.00980958 0.01631003 0.01077275\n",
      " 0.01016464 0.00164935 0.01201909 0.01345858 0.01054308 0.01246479\n",
      " 0.00189483 0.00848166 0.01189495 0.00226414 0.00871032 0.01280831\n",
      " 0.01201529 0.0091875  0.0132896  0.01413383 0.0083716  0.01075297\n",
      " 0.01131163 0.00866148 0.00781889 0.00798044 0.01358306 0.00816582\n",
      " 0.00787996 0.00986716 0.01055781 0.01245516 0.00559471 0.00901723\n",
      " 0.01349356 0.01029195 0.00615882 0.00646616 0.00680286 0.01227652\n",
      " 0.00915185 0.01146637 0.01031809 0.00676416 0.00947115 0.00730678\n",
      " 0.00687184 0.0022958  0.01043746 0.00837449 0.00795457 0.00182517\n",
      " 0.0082859  0.00822529 0.01303836 0.00667884 0.00853634 0.01013017\n",
      " 0.00852789 0.01224895 0.00630303 0.01017482 0.01098564 0.01494719\n",
      " 0.00789689 0.01391384 0.01242932 0.0017009  0.01639154 0.01258241\n",
      " 0.01145775 0.01336677 0.01761915 0.01135941 0.01403542 0.01388494\n",
      " 0.01070144 0.01214065 0.01511402 0.01502419 0.01015592 0.00820689\n",
      " 0.01549813 0.0136297 ]\n",
      "[86, 3, 82, 16, 96, 92, 93, 77, 14, 9, 1, 33, 88, 79, 89, 97, 40, 48, 21, 85, 32, 8, 68, 29, 83, 23, 45, 80, 53, 73, 91, 20, 30, 6, 26, 55, 84, 87, 36, 0, 76, 10, 4, 17, 35, 90, 44, 22, 62, 56, 49, 75, 18, 94, 71, 5, 43, 15, 58, 31, 54, 47, 12, 2, 28, 37, 70, 72, 25, 63, 34, 66, 67, 95, 11, 41, 39, 64, 78, 42, 38, 59, 60, 13, 52, 57, 69, 51, 74, 50, 46, 61, 27, 24, 65, 81, 7, 19]\n",
      "[3, 16, 82, 86, 96]\n",
      "`` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\n",
      "Nevertheless , `` we feel that in the future Fulton County should receive some portion of these available funds '' , the jurors said .\n",
      "-- After a long , hot controversy , Miller County has a new school superintendent , elected , as a policeman put it , in the `` coolest election I ever saw in this county '' .\n",
      "`` This was the coolest , calmest election I ever saw '' , Colquitt Policeman Tom Williams said .\n",
      "`` Everything went real smooth '' , the sheriff said .\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    " \n",
    "sentence_ranks = pagerank(S)\n",
    " \n",
    "print(sentence_ranks)\n",
    " \n",
    "# Get the sentences ordered by rank\n",
    "ranked_sentence_indexes = [item[0] for item in sorted(enumerate(sentence_ranks), key=lambda item: -item[1])]\n",
    "print(ranked_sentence_indexes)\n",
    " \n",
    "# Suppose we want the 5 most import sentences\n",
    "SUMMARY_SIZE = 5\n",
    "SELECTED_SENTENCES = sorted(ranked_sentence_indexes[:SUMMARY_SIZE])\n",
    "print(SELECTED_SENTENCES)\n",
    " \n",
    "# Fetch the most important sentences\n",
    "summary = itemgetter(*SELECTED_SENTENCES)(sentences)\n",
    " \n",
    "# Print the actual summary\n",
    "for sentence in summary:\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. `` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\n",
      "2. Nevertheless , `` we feel that in the future Fulton County should receive some portion of these available funds '' , the jurors said .\n",
      "3. -- After a long , hot controversy , Miller County has a new school superintendent , elected , as a policeman put it , in the `` coolest election I ever saw in this county '' .\n",
      "4. `` This was the coolest , calmest election I ever saw '' , Colquitt Policeman Tom Williams said .\n",
      "5. `` Everything went real smooth '' , the sheriff said .\n"
     ]
    }
   ],
   "source": [
    "def textrank(sentences, top_n=5, stopwords=None):\n",
    "    \"\"\"\n",
    "    sentences = a list of sentences [[w11, w12, ...], [w21, w22, ...], ...]\n",
    "    top_n = how may sentences the summary should contain\n",
    "    stopwords = a list of stopwords\n",
    "    \"\"\"\n",
    "    S = build_similarity_matrix(sentences, stop_words) \n",
    "    sentence_ranks = pagerank(S)\n",
    " \n",
    "    # Sort the sentence ranks\n",
    "    ranked_sentence_indexes = [item[0] for item in sorted(enumerate(sentence_ranks), key=lambda item: -item[1])]\n",
    "    selected_sentences = sorted(ranked_sentence_indexes[:top_n])\n",
    "    summary = itemgetter(*selected_sentences)(sentences)\n",
    "    return summary\n",
    " \n",
    "for idx, sentence in enumerate(textrank(sentences, stopwords=stopwords.words('english'))):\n",
    "    print(\"%s. %s\" % ((idx + 1), ' '.join(sentence)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"Architecturally, the school has a Catholic character.\n",
    "Atop the Main Building's gold dome is a golden statue of the Virgin Mary.\n",
    "Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\".\n",
    "Next to the Main Building is the Basilica of the Sacred Heart.\n",
    "Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.\n",
    "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n",
    "At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The koala (Phascolarctos cinereus, or, inaccurately, koala bear[a]) is an arboreal herbivorous marsupial native to Australia. It is the only extant representative of the family Phascolarctidae and its closest living relatives are the wombats, which comprise the family Vombatidae. The koala is found in coastal areas of the mainland's eastern and southern regions, inhabiting Queensland, New South Wales, Victoria, and South Australia. It is easily recognisable by its stout, tailless body and large head with round, fluffy ears and large, spoon-shaped nose. The koala has a body length of 60–85 cm (24–33 in) and weighs 4–15 kg (9–33 lb). Fur colour ranges from silver grey to chocolate brown. Koalas from the northern populations are typically smaller and lighter in colour than their counterparts further south. These populations possibly are separate subspecies, but this is disputed.\n",
    "\n",
    "Koalas typically inhabit open eucalypt woodlands, and the leaves of these trees make up most of their diet. Because this eucalypt diet has limited nutritional and caloric content, koalas are largely sedentary and sleep up to 20 hours a day. They are asocial animals, and bonding exists only between mothers and dependent offspring. Adult males communicate with loud bellows that intimidate rivals and attract mates. Males mark their presence with secretions from scent glands located on their chests. Being marsupials, koalas give birth to underdeveloped young that crawl into their mothers' pouches, where they stay for the first six to seven months of their lives. These young koalas, known as joeys, are fully weaned around a year old. Koalas have few natural predators and parasites, but are threatened by various pathogens, such as Chlamydiaceae bacteria and the koala retrovirus.\n",
    "\n",
    "Koalas were hunted by Indigenous Australians and depicted in myths and cave art for millennia. The first recorded encounter between a European and a koala was in 1798, and an image of the animal was published in 1810 by naturalist George Perry. Botanist Robert Brown wrote the first detailed scientific description of the koala in 1814, although his work remained unpublished for 180 years. Popular artist John Gould illustrated and described the koala, introducing the species to the general British public. Further details about the animal's biology were revealed in the 19th century by several English scientists. Because of its distinctive appearance, the koala is recognised worldwide as a symbol of Australia. Koalas are listed as Vulnerable by the International Union for Conservation of Nature. The animal was hunted heavily in the early 20th century for its fur, and large-scale cullings in Queensland resulted in a public outcry that initiated a movement to protect the species. Sanctuaries were established, and translocation efforts moved to new regions koalas whose habitat had become fragmented or reduced. Among the many threats to their existence are habitat destruction caused by agriculture, urbanisation, droughts and associated bushfires, some related to climate change.[4] Increased habitat loss may also increase risks from vehicle traffic, dog attacks, pesticides in waterways, and increased food competition.[5][6][7]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a4c8516290b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtextrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-ea9d06da1109>\u001b[0m in \u001b[0;36mtextrank\u001b[1;34m(sentences, top_n, stopwords)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_similarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msentence_ranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-74cca37fe85e>\u001b[0m in \u001b[0;36mbuild_similarity_matrix\u001b[1;34m(sentences, stopwords)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# normalize the matrix row-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-005a391ce685>\u001b[0m in \u001b[0;36msentence_similarity\u001b[1;34m(sent1, sent2, stopwords)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mvector2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcosine_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# One out of 5 words differ => 0.8 similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ml\\datami~1\\jupyte~1\\wikipe~1\\venv\\lib\\site-packages\\nltk\\cluster\\util.py\u001b[0m in \u001b[0;36mcosine_distance\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m|\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m|\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "textrank(text, 5, stopwords=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
